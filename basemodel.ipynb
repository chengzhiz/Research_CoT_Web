{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chapter318/opt/anaconda3/envs/py33/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "from langchain_openai import ChatOpenAI \n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/google-research-datasets/boolean-questions?tab=readme-ov-file\n",
    "#  boolean questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "import requests\n",
    "# https://huggingface.co/google/flan-t5-large?text=Please+give+me+a+simple+question+that+normal+people+ask+a+robot+that+can+be+answered+with+yes%2Fno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# https://huggingface.co/google/flan-t5-large?text=Please+give+me+a+simple+question+that+normal+people+ask+a+robot+that+can+be+answered+with+yes%2Fno.\n",
    "\n",
    "API_URL = \"https://api-inference.huggingface.co/models/google/flan-t5-large\"\n",
    "headers = {\"Authorization\": \"Bearer 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\"}\n",
    "\n",
    "\n",
    "def query(payload):\n",
    "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
    "\treturn response.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the name of the smallest land form on Earth?\n"
     ]
    }
   ],
   "source": [
    "def generate_question():\n",
    "    prompt_variations = [\n",
    "        \"Provide a simple fact-based yes/no question\",\n",
    "        \"Provide a yes/no question that kids would ask\",\n",
    "        \"Provide a yes/no question that adult would ask\",\n",
    "        \"Provide a sophisticated yes/no question\",\n",
    "        \"Provide a complicated yes/no question\",\n",
    "        \"Provide an easy yes/no question\",\n",
    "    ]\n",
    "    prompt = random.choice(prompt_variations)\n",
    "    # prompt = f\"Please give me a simple yes/no question. Random seed: {random.randint(1, 1000)} Time: {datetime.now()}\"\n",
    "    random_question = query({\n",
    "\t\t\"inputs\": prompt,\n",
    "\t})\n",
    "    return random_question[0]['generated_text']\n",
    "\n",
    "print(generate_question())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.py Final Question: What is the best way to get rid of a scab?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:12: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<>:12: SyntaxWarning: invalid escape sequence '\\ '\n",
      "/var/folders/_g/_764cssj41d39tz0k3_y00v80000gn/T/ipykernel_90416/378883912.py:12: SyntaxWarning: invalid escape sequence '\\ '\n",
      "  \"content\": \"You are a robot that answers each question with yes or no and the reason. Firstly, determine if the question is a yes/no question. If it's not, reply with 'None'. If it is a yes/no question, reply with yes/no, and then reply with exactly following sentences:\\n\\\n"
     ]
    }
   ],
   "source": [
    "print(\"model.py Final Question:\", generate_question())\n",
    "\n",
    "def ask_chatgpt(user_input):\n",
    "    \"\"\"Send a question to ChatGPT and return the response.\"\"\"\n",
    "    client = OpenAI()\n",
    "    # Construct the API call to GPT-4 with the appropriate messages, function calling, and response format\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a robot that answers each question with yes or no and the reason. Firstly, determine if the question is a yes/no question. If it's not, reply with 'None'. If it is a yes/no question, reply with yes/no, and then reply with exactly following sentences:\\n\\\n",
    "                1. Personal and Contextual Insight: Chatbots don’t know your personal details and can’t provide advice specific to your life.\\n\\\n",
    "                2. Emotions and Relationships: Chatbots don’t understand emotions or relationships, so they can’t offer advice on personal matters.\\n\\\n",
    "                3. Personal Opinions and Preferences: Chatbots don’t have personal opinions, so they can’t advise on individual tastes.\\n\\\n",
    "                4. Predicting the Future and Speculation: Chatbots can’t predict future events or answer speculative questions. They stick to known facts.\\n\\\n",
    "                5. Medical and Legal Advice: Chatbots aren’t suitable for health or legal advice. Consult a professional in these fields.\\n\\\n",
    "                6. Sensory and Perceptual Limitations: Chatbots work only with text and can’t interpret sounds, images, or physical sensations.\\n\\\n",
    "                7. Artistic and Literary Interpretation: Chatbots lack personal insight, so they can’t interpret art or literature with emotional depth.\\n\\\n",
    "                8. General Knowledge and Fact-Checking: Chatbots excel at general knowledge and fact-checking in areas like history, science, and technology.\\n\\\n",
    "                9. Identity and Personhood: Chatbots are not human. They don’t have identities, genders, or personalities.\\n\\ \"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_input\n",
    "            }\n",
    "        ],\n",
    "        temperature=1,\n",
    "        max_tokens=2048,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        functions=[\n",
    "            {\n",
    "                \"name\": \"answer_categorize_question\",\n",
    "                \"description\": \"Provides a yes/no answer, the category name, and a justification.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"answer\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"enum\": [\"Yes\", \"no\", \"None\"]\n",
    "                        },\n",
    "                        \"category_name\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The full name of the category the question belongs to.\",\n",
    "                            \"enum\": [\n",
    "                                \"Personal and Contextual Insight\",\n",
    "                                \"Emotions and Relationships\",\n",
    "                                \"Personal Opinions and Preferences\",\n",
    "                                \"Predicting the Future and Speculation\",\n",
    "                                \"Medical and Legal Advice\",\n",
    "                                \"Sensory and Perceptual Limitations\",\n",
    "                                \"Questions Involving Human Emotions or Relationships\",\n",
    "                                \"Interpretation of Art or Literature\",\n",
    "                                \"General Knowledge and Fact-Checking\",\n",
    "                                \"Identity and Personhood\"\n",
    "                            ]\n",
    "                        },\n",
    "                        \"justification\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"A one-sentence justification for why the question belongs to the category.\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"answer\", \"category_name\", \"justification\"]\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "        function_call=\"auto\"  # Automatically call the function\n",
    "    )\n",
    "\n",
    "    # print(response)\n",
    "    # Extract the function call from the response\n",
    "    try:\n",
    "        function_call = response.choices[0].message.function_call\n",
    "        # print(function_call)\n",
    "    except AttributeError:\n",
    "        return {\n",
    "            \"answer\": \"None\",\n",
    "            \"category_name\": \"None\",\n",
    "            \"justification\": \"None\"\n",
    "        }\n",
    "    # Parse the arguments of the function call\n",
    "\n",
    "    try:\n",
    "        arguments = function_call.arguments\n",
    "        # print(arguments)\n",
    "    except AttributeError:\n",
    "        return {\n",
    "            \"answer\": \"None\",\n",
    "            \"category_name\": \"None\",\n",
    "            \"justification\": \"None\"\n",
    "        }\n",
    "\n",
    "\n",
    "    parsed_data = json.loads(arguments)\n",
    "    # Display the output: Answer, Category Name, and Justification\n",
    "    answer = parsed_data[\"answer\"]\n",
    "    category_name = parsed_data[\"category_name\"]\n",
    "    justification = parsed_data[\"justification\"]\n",
    "\n",
    "    # Returning the structured response\n",
    "    return {\n",
    "        \"answer\": answer,\n",
    "        \"category_name\": category_name,\n",
    "        \"justification\": justification\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel.py Final Answer:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mask_chatgpt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerate_question\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m, in \u001b[0;36mask_chatgpt\u001b[0;34m(user_input)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mask_chatgpt\u001b[39m(user_input):\n\u001b[1;32m      4\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Send a question to ChatGPT and return the response.\"\"\"\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m     client \u001b[38;5;241m=\u001b[39m \u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Construct the API call to GPT-4 with the appropriate messages, function calling, and response format\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m      8\u001b[0m         model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      9\u001b[0m         messages\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     69\u001b[0m         function_call\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Automatically call the function\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py33/lib/python3.12/site-packages/openai/_client.py:105\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[0;34m(self, api_key, organization, project, base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m    103\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[1;32m    106\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    107\u001b[0m     )\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m api_key\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m organization \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "print(\"model.py Final Answer:\", ask_chatgpt(generate_question()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runModels():\n",
    "    results = ask_chatgpt(generate_question())\n",
    "    return results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py33",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
